# ─── BYOK: Bring Your Own Key ──────────────────────────
# c0 works with ANY OpenAI-compatible API provider.
# Just set the base URL and API key for your provider.

# ─── OpenRouter (recommended for multi-model access) ───
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-v1-...
LLM_MODEL=anthropic/claude-sonnet-4

# ─── OpenAI ────────────────────────────────────────────
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=sk-...
# LLM_MODEL=gpt-4o

# ─── Anthropic (via OpenAI-compatible proxy) ───────────
# LLM_BASE_URL=https://api.anthropic.com/v1/
# LLM_API_KEY=sk-ant-...
# LLM_MODEL=claude-sonnet-4-20250514

# ─── Groq ──────────────────────────────────────────────
# LLM_BASE_URL=https://api.groq.com/openai/v1
# LLM_API_KEY=gsk_...
# LLM_MODEL=llama-3.3-70b-versatile

# ─── Local Ollama ──────────────────────────────────────
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_MODEL=llama3.2
